{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import re\n",
    "import json\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from youtube_transcript_api import YouTubeTranscriptApi\n",
    "from get_timestamps import get_timestamps, get_text\n",
    "from yt_dlp import YoutubeDL\n",
    "import whisper\n",
    "from transformers import pipeline\n",
    "from datasets import load_dataset, Audio\n",
    "\n",
    "model = whisper.load_model(\"medium.en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_srt_to_json(srt):\n",
    "    \"\"\" \n",
    "    From YouTubeTranscriptAPI we get a srt file,\n",
    "    this function converts it to a json file and \n",
    "    formats it in the same structure as Whisper output.\n",
    "    \"\"\"\n",
    "    json_list = []\n",
    "\n",
    "    for dict in srt:\n",
    "        start_time = dict[\"start\"]\n",
    "        end_time = dict[\"start\"] + dict[\"duration\"]\n",
    "        json_list.append(\n",
    "            {\n",
    "                \"start\": start_time,\n",
    "                \"end\": end_time,\n",
    "                \"text\": dict[\"text\"],\n",
    "            }\n",
    "        )\n",
    "    \n",
    "    result = {\"segments\":json_list}\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_timestamps_times(description):\n",
    "    \"\"\"GitHub copilot did this. I'm bad at regex but it's pretty simple in this case\"\"\"\n",
    "    timestamps = []\n",
    "    timestamp_regex = r\"\\d{1,2}:\\d{2}:\\d{2}|\\d{1,2}:\\d{2}\"\n",
    "    timestamp_matches = re.findall(timestamp_regex, description)\n",
    "    for timestamp in timestamp_matches:\n",
    "        timestamps.append(timestamp)\n",
    "    return timestamps\n",
    "\n",
    "def get_timestamps_keywords(description, timestamps):\n",
    "    \"\"\"\n",
    "    Extract description text for each timestamp.\n",
    "    Split the description on each timestamp time, then remove the time part.\n",
    "    split by newline and take out the keyword for the timestamp.\n",
    "    Then do some processing, remove -, brackets, unecessary space.\n",
    "    \"\"\"\n",
    "    keywords = []\n",
    "    for timestamp in timestamps:\n",
    "        chapter = description.split(timestamp)[1].split(\"\\n\")[0]\n",
    "        chapter = chapter.strip().strip(\"-\").strip(\"[\").strip(\"|\").strip(\"]\").strip()\n",
    "        keywords.append(chapter)\n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_transcript_from_API(video_id):\n",
    "    \"\"\"Download transcript from YouTube API\"\"\"\n",
    "    srt = YouTubeTranscriptApi.get_transcript(video_id)\n",
    "    transcript = convert_srt_to_json(srt)\n",
    "    return transcript"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def download_audio(url, output_file):\n",
    "    # Download audio file from a youtube url using yt-dlp\n",
    "    ffmpeg_loc = \"C:/Users/aladd/Desktop/Shortcuts/ffmpeg/bin/ffmpeg.exe\"\n",
    "\n",
    "    \"\"\"\n",
    "    Download audio file from a youtube url using yt-dlp\n",
    "    \"\"\"\n",
    "    ydl_opts = {\n",
    "        \"format\": \"bestaudio/best\",\n",
    "        \"outtmpl\": output_file,\n",
    "        \"ffmpeg_location\": ffmpeg_loc,\n",
    "        \"postprocessors\": [\n",
    "            {\n",
    "                \"key\": \"FFmpegExtractAudio\",\n",
    "                \"preferredcodec\": \"wav\",\n",
    "                \"preferredquality\": \"196\",\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    with YoutubeDL(ydl_opts) as ydl:\n",
    "        ydl.download([url])\n",
    "\n",
    "\n",
    "def download_transcript_using_whisper(video_id, output_file=\"audio/audio.wav\"):\n",
    "    # make video_id into youtube url\n",
    "    url = f\"https://www.youtube.com/watch?v={video_id}\"\n",
    "\n",
    "    # delete audio.wav if it exists\n",
    "    if os.path.exists(output_file):\n",
    "        os.remove(output_file)\n",
    "        \n",
    "    # download audio file\n",
    "    download_audio(url, output_file)\n",
    "\n",
    "    # transcript using whisper\n",
    "    # time how long it takes \n",
    "    start = time.time()\n",
    "    result = model.transcribe(output_file, verbose=True)\n",
    "    end = time.time()\n",
    "    print(f\"Whisper model took {end-start} seconds to transcribe\")\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 951/951 [09:38<00:00,  1.64it/s]\n"
     ]
    }
   ],
   "source": [
    "DATA_FILE = \"youtube_data_v3_extra_1.csv\"\n",
    "DIR_FOLDER = \"raw_dataset_v3\"\n",
    "\n",
    "if not os.path.exists(DIR_FOLDER):\n",
    "    os.mkdir(DIR_FOLDER)\n",
    "\n",
    "df = pd.read_csv(DATA_FILE)\n",
    "urls = df[\"url\"].tolist()\n",
    "descriptions = df[\"description\"].tolist()\n",
    "tags = df[\"tags\"].tolist()\n",
    "titles = df[\"title\"].tolist()\n",
    "likes = df[\"likes\"].tolist()\n",
    "durations = df[\"duration\"].tolist()\n",
    "comments = df[\"top_comment\"].tolist()\n",
    "\n",
    "assert len(urls) == len(descriptions) == len(tags) == len(titles) == len(likes) == len(durations)\n",
    "\n",
    "# loop through urls and download audio\n",
    "for idx in tqdm(range(len(urls))):\n",
    "    video_id = urls[idx].split(\"=\")[1]\n",
    "    description = descriptions[idx]\n",
    "    tag = tags[idx]\n",
    "    title = titles[idx]\n",
    "    like = likes[idx]\n",
    "    duration = durations[idx]\n",
    "    comment = comments[idx]\n",
    "\n",
    "    # get timestamps\n",
    "    try:\n",
    "        timestamps = get_timestamps_times(description)\n",
    "        keywords = get_timestamps_keywords(description, timestamps)\n",
    "    except:\n",
    "        timestamps = []\n",
    "        keywords = []\n",
    "        #print(f\"Error getting timestamps for {video_id}\")\n",
    "\n",
    "    # check if video_id.json in transcripts folder\n",
    "    if video_id + \".json\" not in os.listdir(DIR_FOLDER):\n",
    "        # check in length of timestamps is greater than 0\n",
    "        try:\n",
    "            result = download_transcript_from_API(video_id)\n",
    "        except:\n",
    "            #print(f\"Probably a private video {video_id} or no transcript. Downloading using whisper\")\n",
    "            try:\n",
    "                pass\n",
    "                #result = download_transcript_using_whisper(video_id)\n",
    "            except:\n",
    "                print(f\"Error downloading with Whisper transcript for {video_id}\")\n",
    "                continue\n",
    "\n",
    "\n",
    "        # Add metadata to json file\n",
    "        result[\"video_id\"] = video_id\n",
    "        result[\"description\"] = description\n",
    "        result[\"tags\"] = tag\n",
    "        result[\"title\"] = title\n",
    "        result[\"likes\"] = like\n",
    "        result[\"duration\"] = duration\n",
    "        result[\"timestamps\"] = timestamps\n",
    "        result[\"keywords\"] = keywords\n",
    "        result[\"comment\"] = comment\n",
    "\n",
    "        # Save json file\n",
    "        with open(f\"{DIR_FOLDER}/{video_id}.json\", \"w\") as f:\n",
    "            json.dump(result, f)\n",
    "    else:\n",
    "        pass\n",
    "        #print(f\"{video_id} already exists\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.15 ('ythelper')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15 (main, Nov 24 2022, 14:39:17) [MSC v.1916 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2f6c81a6c2acde1c8a96f2afe16e136fb286d5a04c0643ed36c3def4138fcfe6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
